# ch14. 유튜브 설계

- Q). 비디오 트랜스코딩 작업은 복잡한 파이프라인이 필요한데, 어떤 도구를 통해 파이프라인을 관리할 지?
- Q). Blob 저장소 사용해 본 적 있는지? 무엇인지 설명해줄 수 있나요?

## 비디오 스트리밍 프로토콜
1) 온디맨드 스트리밍 (VOD, Video On Demand)
- 사용자가 원할 때 영상 콘텐츠를 즉시 재생
- YouTube, Netflix, Disney+ 등이 사용
- HTTP 기반 프로토콜(HLS, DASH) 사용
2) 라이브 스트리밍 (Live Streaming)
- 실시간으로 방송하며 시청자가 동시에 시청
- YouTube Live, Twitch, Facebook Live 등이 사용
- RTMP, HLS, WebRTC 등 저지연 프로토콜 사용

## 브라우저 youtube 요청 작동 방식
1. 사용자 브라우저: https://www.youtube.com/watch?v=12345 요청
2. YouTube 서버: HTML 페이지 전송, 비디오 플레이어(JavaScript) 포함
3. 브라우저: 비디오 재생 시 CDN 서버에 HTTP 요청 (GET https://r1---sn-abcxyz.googlevideo.com/videoplayback?...), 비디오 파일은 .m3u8(HLS), .mpd(DASH) 등의 스트림 조각(Chunk) 형태로 전송됨
4. CDN 서버: 가장 가까운 Edge 서버에서 비디오 조각(.ts, .m4s) 전송
5. 브라우저: 비디오 플레이어가 Chunk 단위로 다운로드 후 순차적으로 재생(Buffering)
-> 브라우저는 각 Chunk를 개별적인 HTTP 요청으로 다운로드하여 순차 재생(Buffering)합니다.

## Blob storage
| **스토리지 유형** | **설명** | **주요 사용 사례** |
|------------------|---------|-------------------|
| Blob Storage | 비정형 데이터(이미지, 비디오, 로그) 저장 | 대용량 파일 저장, 백업 |
| File Storage | 파일 시스템 기반 저장, 계층 구조 | 네트워크 드라이브, 공유 폴더 |
| Block Storage | OS, DB 등을 위한 블록 단위 저장 | SSD, HDD, VM 디스크 |
| Object Storage | 메타데이터와 함께 파일 저장 | 클라우드 백업, 데이터 아카이빙 |

- object storage: 클라우드 저장소, 파일을 객체로 저장하여 무한 확장 가능, AWS S3
- file system: 단일 노드에서 저장하는 트리 구조
- distributed file system: 여러 노드에서 저장하는 트리 구조, HDFS (hadoop) 같은게 있음

## DAG 케이스
- workflow 
- data pipeline (ETL)

### DAG -> 2개의 docker container 를 실행하는 예제
```python
from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator
from datetime import datetime

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 2, 25),
    'retries': 1,
}

with DAG(
    dag_id="docker_sequential_execution",
    default_args=default_args,
    schedule_interval=None,  # 수동 실행
    catchup=False,
) as dag:

    # 첫 번째 Docker 컨테이너 실행 (Ubuntu에서 echo 실행)
    task1 = DockerOperator(
        task_id="run_first_container",
        image="ubuntu:latest",
        api_version="auto",
        auto_remove=True,  # 컨테이너 종료 후 자동 삭제
        command="echo 'Hello from Container 1!'",
        docker_url="unix://var/run/docker.sock",
        network_mode="bridge",
    )

    # 두 번째 Docker 컨테이너 실행 (Python 컨테이너에서 print 실행)
    task2 = DockerOperator(
        task_id="run_second_container",
        image="python:3.9",
        api_version="auto",
        auto_remove=True,
        command="python -c \"print('Hello from Container 2!')\"",
        docker_url="unix://var/run/docker.sock",
        network_mode="bridge",
    )

    task1 >> task2  # 첫 번째 컨테이너가 끝난 후 두 번째 컨테이너 실행

```
