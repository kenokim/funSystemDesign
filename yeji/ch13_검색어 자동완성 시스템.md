## 조건

- 검색어의 첫 부분, 5개 , 인기순, 맞춤법제외, 영어, 소문자, 천만 dau,
- 요구사항
    - 100ms 이내의 빠른 응답 속도
    - 연관있는 단어
    - 인기순으로 정렬
    - 많은 트래픽을 감당하도록 확장 가능
    - 고가용성 ( 문제가 생겨도 사용 가능)
- 규모 :
    - 천만 dau, 평균 20바이트 (4단어 *5글자)
    - 초당 각 글자를 입력한 24000건의 질의 qps, 최대는 48000qps
    - 20%정도가 신규 검색어 (0.4GB)

## 구조

## 데이터 수집 서비스

- 질의문 , 빈도 수집
- 입력을 실시간으로 수집 → 데이터가 많은 실시간 시스템에 비적합
- 한번 트라이가 만들어진 뒤에는 인기 검색어가 자주 바뀔 필요는 없음
    
- 데이터 분석 서비스 로그 : 검색창에 입력된 질의에 대한 원본 데이터 ( 검색어,시간)
- 로그 취합 서버 : aggregation 하여 데이터 정제, 취합주기는 어플리케이션 성격에 따라, 일주일- (검색어, 시간-주의 시작일, 빈도)
- 작업 서버 : 비동기적으로 작업, 트라이 자료구조를 만들고 데이터베이스에 저장한다 (매주 갱신ㅡ 각 노드를 개별적으로 갱신하는건 성능이 좋지 않음)
- 트라이 캐시 : 분산시스템, 데이터를 메모리에 유지, 데이터베이스의 스냅샷을 떠서 갱신
- 트라이 데이터 베이스 :
    - 문서 저장소 - 매주 새 트라이를 직렬화하여 데이터베이스에 저장
    - 키값 저장소 - 모든 접두어를 해시 테이블 키로 변환, 각 트라이 노드의 모든 데이터를 값으로 변환
    - 규모확장성 - 첫글자 기준 샤딩, 최대 26대의 서버, 이상으로 늘리는 경우 계층적으로 샤딩 → 균등하게 배분이 어려움( 시작 글자별 갯수 차이 등) → 과거 질의 데이터의 패턴을 분석하여 샤딩
- 검색어 삭제 : 혐오적 표현은 결과에서 제거해야함. api 요청 시 트라이 캐시 앞에 필터 계층을 두어 거름. 데이터베이스에서 삭제하는것은 다음 업데이트 사이클에 비동기적으로 진행

## 질의 서비스

- 관계형 db에 like문으로 빈도를 기준으로 sql 질의 → 데이터가 적을 때만 가능
- 요청 → 로드밸런서 → 서버 → 트라이캐시에서 데이터를 가져옴 → 없는경우 데이터베이스 조회후 캐시에 저장
- ajax 요청, 브라우저 캐싱, 데이터 샘플링(여러개 요청 중 한개만 로깅)

## 자료 구조 : 트라이(trie) 접두어트리 사용

- 노드에 문자 저장 t→ tr→tre→tree:10
- P 접두어의 길이, n : 트라이안의 노드 수 , c : 주어진 노드의 자식 수
- 해당 접두어 노드를 찾음 (p)→ 해당 노드부터 하위 트리의 유효 노드를 찾음 (c)→ 유효노드를 정렬하여 가장 인기있는 검색어를 찾음 (clogc)
    - 최악의 경우 전체 검색
    - → 최대 길이 제한 : p→1
    - → 노드에 인기 검색어 캐시 : 각 노드에 인기검색어를 저장(저장 공간을 많이 소모하나 응답속도가 빨라짐) clogc→ 1
    
    

## 확장 질문

- 다국어 지원 → 유니코드 데이터
- 국가별 → 국가별 트라이 ,cdn에 저장 가능


- 데이터 삭제는 어떻게 ?
- 이 경우는 단어만 제공, 문장인경우도 단어처럼?
